{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://raw.githubusercontent.com/openvinotoolkit/anomalib/main/docs/source/images/logos/anomalib-wide-blue.png\" alt=\"Paris\" class=\"center\"></center>\n",
    "\n",
    "<center>ðŸ’™ A library for benchmarking, developing and deploying deep learning anomaly detection algorithms</center>\n",
    "\n",
    "______________________________________________________________________\n",
    "\n",
    "> NOTE:\n",
    "> This notebook is originally created by @innat on [Kaggle](https://www.kaggle.com/code/ipythonx/mvtec-ad-anomaly-detection-with-anomalib-library/notebook). This is a modified version, which connects the code with Picsellia platform\n",
    "\n",
    "[Anomalib](https://github.com/openvinotoolkit/anomalib): Anomalib is a deep learning library that aims to collect state-of-the-art anomaly detection algorithms for benchmarking on both public and private datasets. Anomalib provides several ready-to-use implementations of anomaly detection algorithms described in the recent literature, as well as a set of tools that facilitate the development and implementation of custom models. The library has a strong focus on image-based anomaly detection, where the goal of the algorithm is to identify anomalous images, or anomalous pixel regions within images in a dataset.\n",
    "\n",
    "The library supports [`MVTec AD`](https://www.mvtec.com/company/research/datasets/mvtec-ad) (CC BY-NC-SA 4.0) and [`BeanTech`](https://paperswithcode.com/dataset/btad) (CC-BY-SA) for **benchmarking** and `folder` for custom dataset **training/inference**. In this notebook, we will explore `anomalib` training a PADIM model on the `MVTec AD` bottle dataset and evaluating the model's performance. The sections in this notebook explores the steps in `tools/train.py` more in detail. Those who would like to reproduce the results via CLI could use `python tools/train.py --model padim`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Anomalib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation can be done in two ways: (i) install via PyPI, or (ii) installing from sourc, both of which are shown below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Install via PyPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option - I: Uncomment the next line if you want to install via pip.\n",
    "%pip install anomalib"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Install Picsellia package"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -r requirements/base.txt\n",
    "!pip install -r requirements/openvino.txt\n",
    "!pip install picsellia\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now let's verify the working directory. This is to access the datasets and configs when the notebook is run from different platforms such as local or Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# from git.repo import Repo\n",
    "\n",
    "current_directory = Path.cwd()\n",
    "if current_directory.name == \"000_getting_started\":\n",
    "    # On the assumption that, the notebook is located in\n",
    "    #   ~/anomalib/notebooks/000_getting_started/\n",
    "    root_directory = current_directory.parent.parent\n",
    "elif current_directory.name == \"anomalib\":\n",
    "    # This means that the notebook is run from the main anomalib directory.\n",
    "    root_directory = current_directory\n",
    "# else:\n",
    "#     # Otherwise, we'll need to clone the anomalib repo to the `current_directory`\n",
    "#     repo = Repo.clone_from(url=\"https://github.com/openvinotoolkit/anomalib.git\", to_path=current_directory)\n",
    "#     root_directory = current_directory / \"anomalib\"\n",
    "\n",
    "os.chdir(root_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pytorch_lightning import Trainer\n",
    "from anomalib.config import get_configurable_parameters\n",
    "from anomalib.data import get_datamodule\n",
    "from anomalib.models import get_model\n",
    "from anomalib.pre_processing.transforms import Denormalize\n",
    "from anomalib.utils.callbacks import LoadModelCallback, get_callbacks\n",
    "from picsellia import Client\n",
    "from picsellia.types.enums import LogType\n",
    "from picsellia.exceptions import ResourceNotFoundError\n",
    "\n",
    "from utils import SaveTrainingMetrics,GetMaskPredictions, show_image_and_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Connect to Picsellia and get experiment\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "api_token = \"\"\n",
    "client = Client(api_token=api_token, organization_name=\"\")\n",
    "experiment_id = \"\"\n",
    "experiment = client.get_experiment_by_id(experiment_id)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"patchcore\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the dataset from Picsellia"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for dataset_type in ['good', 'abnormal', 'mask']:\n",
    "    assets = experiment.get_dataset(dataset_type)\n",
    "    assets.download(os.path.join(root_directory, experiment.png_dir, dataset_type))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Write to Config File"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    config = experiment.get_artifact('config')\n",
    "    config.download(experiment.config_dir)\n",
    "    config_fullpath = os.path.join(experiment.config_dir, config.filename)\n",
    "except ResourceNotFoundError:\n",
    "    config_fullpath = os.path.join(root_directory, \"src\", \"anomalib\", \"models\", \"patchcore\", \"config.yaml\")\n",
    "config_data = yaml.safe_load(open(config_fullpath, 'r'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get experiment's parameters\n",
    "try:\n",
    "    parameters = experiment.get_log(name='parameters').data\n",
    "except ResourceNotFoundError:\n",
    "    parameters = {}\n",
    "batch_size = parameters.get(\"batch_size\", 4)\n",
    "max_epochs = parameters.get(\"max_epochs\", 5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_name = experiment.get_dataset(name='good').name\n",
    "config_data['dataset']['name'] = dataset_name\n",
    "config_data['dataset']['format'] = 'folder'\n",
    "config_data['dataset']['root'] = os.path.join(root_directory, experiment.png_dir)\n",
    "config_data['dataset']['path'] = os.path.join(root_directory, experiment.png_dir)\n",
    "config_data['dataset']['normal_dir'] = 'good'\n",
    "config_data['dataset']['normal_test_dir'] = None\n",
    "\n",
    "config_data['dataset']['abnormal_dir'] = 'abnormal'\n",
    "config_data['dataset']['mask_dir'] = 'mask'\n",
    "config_data['dataset']['task'] = 'segmentation'\n",
    "config_data['dataset']['train_batch_size'] = batch_size\n",
    "config_data['dataset']['extensions'] = None\n",
    "config_data['trainer']['max_epochs'] = max_epochs\n",
    "\n",
    "config_data['project']['path'] = os.path.join(root_directory, experiment.results_dir)\n",
    "\n",
    "config_data['model']['name'] = MODEL\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(config_fullpath, 'w') as cfg:\n",
    "    cfg.write( yaml.dump(config_data, default_flow_style=False))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the config file to model, callbacks and datamodule\n",
    "config = get_configurable_parameters(config_path=config_fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = get_datamodule(config)\n",
    "datamodule.prepare_data()  # Downloads the dataset if it's not in the specified `root` directory\n",
    "datamodule.setup()  # Create train/val/test/prediction sets.\n",
    "\n",
    "i, data = next(enumerate(datamodule.val_dataloader()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the shapes of the input images and masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"image\"].shape, data[\"mask\"].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could now visualize a normal and abnormal sample from the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize an image with a mask\n",
    "show_image_and_mask(data, index=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model and Callbacks\n",
    "\n",
    "Now, the config file is updated as we want. We can now start model training with it. Here we will be using `datamodule`, `model` and `callbacks` to train the model. Callbacks are self-contained objects, which contains non-essential logic. This way we could inject as many callbacks as possible such as ModelLoading, Timer, Metrics, Normalization and Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the export-mode to OpenVINO to create the OpenVINO IR model.\n",
    "config.optimization.export_mode = \"openvino\"\n",
    "# config.optimization.export_mode = \"onnx\"\n",
    "\n",
    "try:\n",
    "    checkpoint_file = experiment.get_artifact('checkpoints')\n",
    "    loaded_checkpoint_path = os.path.join(root_directory, experiment.checkpoint_dir)\n",
    "    checkpoint_file.download(loaded_checkpoint_path)\n",
    "except ResourceNotFoundError as e:\n",
    "    loaded_checkpoint_path = None\n",
    "\n",
    "model = get_model(config)\n",
    "callbacks = get_callbacks(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "callbacks.insert(len(callbacks), SaveTrainingMetrics(experiment))\n",
    "callbacks.insert(len(callbacks), GetMaskPredictions(experiment))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(**config.trainer, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if loaded_checkpoint_path:\n",
    "    load_model_callback = LoadModelCallback(weights_path=os.path.join(loaded_checkpoint_path, checkpoint_file.filename))\n",
    "    trainer.callbacks.insert(0, load_model_callback)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.fit(model=model, datamodule=datamodule)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model from checkpoint before evaluating\n",
    "load_model_callback = LoadModelCallback(weights_path=trainer.checkpoint_callback.best_model_path)\n",
    "# load_model_callback = LoadModelCallback(weights_path=os.path.join(os.path.join(root_directory, experiment.checkpoint_dir, checkpoint_file.filename)))\n",
    "trainer.callbacks.insert(0, load_model_callback)\n",
    "test_results = trainer.test(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Log test results to Picsellia"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment.log(name=\"test_results\", type=LogType.TABLE, data=test_results[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# log example predictions\n",
    "test_image_path = os.path.join(root_directory,experiment.results_dir,MODEL,dataset_name,'run/images/abnormal')\n",
    "for ele in os.listdir(test_image_path)[:3]:\n",
    "    experiment.log(name='abnormal prediction_'+ele, type=LogType.IMAGE, data=os.path.join(test_image_path,ele))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Log best model's checkpoints to Picsellia"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment.store('checkpoints', trainer.checkpoint_callback.best_model_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Log openvino and onnx models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_root = os.path.join(root_directory, experiment.results_dir, MODEL, dataset_name,'run/weights/openvino/')\n",
    "experiment.store('openvino_metadata', os.path.join(model_root,'metadata.json'))\n",
    "experiment.store('openvino_bin', os.path.join(model_root,'metadata.json'))\n",
    "experiment.store('model_onnx', os.path.join(model_root,'model.onnx'))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae223df28f60859a2f400fae8b3a1034248e0a469f5599fd9a89c32908ed7a84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
