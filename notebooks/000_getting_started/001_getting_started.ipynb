{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://raw.githubusercontent.com/openvinotoolkit/anomalib/main/docs/source/images/logos/anomalib-wide-blue.png\" alt=\"Paris\" class=\"center\"></center>\n",
    "\n",
    "<center>ðŸ’™ A library for benchmarking, developing and deploying deep learning anomaly detection algorithms</center>\n",
    "\n",
    "______________________________________________________________________\n",
    "\n",
    "> NOTE:\n",
    "> This notebook is originally created by @innat on [Kaggle](https://www.kaggle.com/code/ipythonx/mvtec-ad-anomaly-detection-with-anomalib-library/notebook).\n",
    "\n",
    "[Anomalib](https://github.com/openvinotoolkit/anomalib): Anomalib is a deep learning library that aims to collect state-of-the-art anomaly detection algorithms for benchmarking on both public and private datasets. Anomalib provides several ready-to-use implementations of anomaly detection algorithms described in the recent literature, as well as a set of tools that facilitate the development and implementation of custom models. The library has a strong focus on image-based anomaly detection, where the goal of the algorithm is to identify anomalous images, or anomalous pixel regions within images in a dataset.\n",
    "\n",
    "The library supports [`MVTec AD`](https://www.mvtec.com/company/research/datasets/mvtec-ad) (CC BY-NC-SA 4.0) and [`BeanTech`](https://paperswithcode.com/dataset/btad) (CC-BY-SA) for **benchmarking** and `folder` for custom dataset **training/inference**. In this notebook, we will explore `anomalib` training a PADIM model on the `MVTec AD` bottle dataset and evaluating the model's performance. The sections in this notebook explores the steps in `tools/train.py` more in detail. Those who would like to reproduce the results via CLI could use `python tools/train.py --model padim`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Anomalib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation can be done in two ways: (i) install via PyPI, or (ii) installing from sourc, both of which are shown below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Install via PyPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option - I: Uncomment the next line if you want to install via pip.\n",
    "%pip install anomalib"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Install Picsellia package"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -r requirements/base.txt\n",
    "!pip install -r requirements/openvino.txt\n",
    "!pip install picsellia\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now let's verify the working directory. This is to access the datasets and configs when the notebook is run from different platforms such as local or Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T11:18:10.647676214Z",
     "start_time": "2023-05-31T11:18:10.646784812Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "# from git.repo import Repo\n",
    "\n",
    "current_directory = Path.cwd()\n",
    "if current_directory.name == \"000_getting_started\":\n",
    "    # On the assumption that, the notebook is located in\n",
    "    #   ~/anomalib/notebooks/000_getting_started/\n",
    "    root_directory = current_directory.parent.parent\n",
    "elif current_directory.name == \"anomalib\":\n",
    "    # This means that the notebook is run from the main anomalib directory.\n",
    "    root_directory = current_directory\n",
    "# else:\n",
    "#     # Otherwise, we'll need to clone the anomalib repo to the `current_directory`\n",
    "#     repo = Repo.clone_from(url=\"https://github.com/openvinotoolkit/anomalib.git\", to_path=current_directory)\n",
    "#     root_directory = current_directory / \"anomalib\"\n",
    "\n",
    "os.chdir(root_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pytorch_lightning import Trainer\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "from anomalib.config import get_configurable_parameters\n",
    "from anomalib.data import get_datamodule\n",
    "from anomalib.models import get_model\n",
    "from anomalib.pre_processing.transforms import Denormalize\n",
    "from anomalib.utils.callbacks import LoadModelCallback, get_callbacks\n",
    "from picsellia import Client\n",
    "from picsellia.types.enums import LogType\n",
    "from picsellia.exceptions import ResourceNotFoundError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from skimage.measure import approximate_polygon, find_contours\n",
    "from typing import List, Tuple\n",
    "from pytorch_lightning.utilities.types import STEP_OUTPUT\n",
    "from typing import Optional\n",
    "import os\n",
    "from anomalib.data.utils import read_image\n",
    "\n",
    "def get_formatted_polygons_from_mask(mask: np.ndarray, img_shape: Tuple[int, int]) -> List:\n",
    "    mask = resize(mask, img_shape)\n",
    "    polygons = convert_mask_to_polygons(mask)\n",
    "    formatted_polygons = format_polygons(polygons=polygons)\n",
    "    return formatted_polygons\n",
    "\n",
    "def convert_mask_to_polygons(mask: np.ndarray) -> List[np.ndarray]:\n",
    "    polygons = []\n",
    "    contours = find_contours(mask, 0)\n",
    "    for contour in contours:\n",
    "        approximated_contour = approximate_polygon(coords=contour, tolerance=0.2)\n",
    "        shifted_contour = shift_x_and_y_coordinates(approximated_contour)\n",
    "        polygons.append(shifted_contour)\n",
    "    return polygons\n",
    "\n",
    "def format_polygons(polygons: List[np.ndarray]) -> List[List[List[int]]]:\n",
    "    formatted_polygons = []\n",
    "    for polygon in polygons:\n",
    "        formatted_polygon = list(polygon.ravel().astype(int))\n",
    "        # format into a list of lists of coordinate pairs\n",
    "        formatted_polygon = [[int(formatted_polygon[k]), int(formatted_polygon[k+1])] for k in range(0, len(formatted_polygon), 2)]\n",
    "        formatted_polygon.append(formatted_polygon[0])\n",
    "\n",
    "        formatted_polygons.append(formatted_polygon)\n",
    "\n",
    "    return formatted_polygons\n",
    "\n",
    "\n",
    "def shift_x_and_y_coordinates(polygon: np.ndarray) -> np.ndarray:\n",
    "    shifted_contours = np.zeros_like(polygon)\n",
    "    shifted_contours[:, 0] = polygon[:, 1]\n",
    "    shifted_contours[:, 1] = polygon[:, 0]\n",
    "    return shifted_contours"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Connect to Picsellia and get experiment\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "api_token = \"\"\n",
    "client = Client(api_token=api_token, organization_name=\"\")\n",
    "experiment_id = \"\"\n",
    "experiment = client.get_experiment_by_id(experiment_id)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T11:19:22.523379761Z",
     "start_time": "2023-05-31T11:19:22.517590825Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL = \"patchcore\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the dataset from Picsellia"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for dataset_type in ['good', 'abnormal', 'mask']:\n",
    "    assets = experiment.get_dataset(dataset_type)\n",
    "    assets.download(os.path.join(root_directory, experiment.png_dir, dataset_type))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Write to Config File"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    config = experiment.get_artifact('config')\n",
    "    config.download(experiment.config_dir)\n",
    "    config_fullpath = os.path.join(experiment.config_dir, config.filename)\n",
    "except ResourceNotFoundError:\n",
    "    config_fullpath = os.path.join(root_directory, \"src\", \"anomalib\", \"models\", \"patchcore\", \"config.yaml\")\n",
    "config_data = yaml.safe_load(open(config_fullpath, 'r'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T11:19:39.355450315Z",
     "start_time": "2023-05-31T11:19:39.293537880Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get experiment's parameters\n",
    "try:\n",
    "    parameters = experiment.get_log(name='parameters').data\n",
    "except ResourceNotFoundError:\n",
    "    parameters = {}\n",
    "batch_size = parameters.get(\"batch_size\", 4)\n",
    "max_epochs = parameters.get(\"max_epochs\", 5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T11:19:43.749718511Z",
     "start_time": "2023-05-31T11:19:43.692876844Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_name = experiment.get_dataset(name='good').name\n",
    "config_data['dataset']['name'] = dataset_name\n",
    "config_data['dataset']['format'] = 'folder'\n",
    "config_data['dataset']['root'] = os.path.join(root_directory, experiment.png_dir)\n",
    "config_data['dataset']['path'] = os.path.join(root_directory, experiment.png_dir)\n",
    "config_data['dataset']['normal_dir'] = 'good'\n",
    "config_data['dataset']['normal_test_dir'] = None\n",
    "\n",
    "config_data['dataset']['abnormal_dir'] = 'abnormal'\n",
    "config_data['dataset']['mask_dir'] = 'mask'\n",
    "config_data['dataset']['task'] = 'segmentation'\n",
    "config_data['dataset']['train_batch_size'] = batch_size\n",
    "config_data['dataset']['extensions'] = None\n",
    "config_data['trainer']['max_epochs'] = max_epochs\n",
    "\n",
    "config_data['project']['path'] = os.path.join(root_directory, experiment.results_dir)\n",
    "\n",
    "config_data['model']['name'] = MODEL\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T11:19:44.584616955Z",
     "start_time": "2023-05-31T11:19:44.517465916Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(config_fullpath, 'w') as cfg:\n",
    "    cfg.write( yaml.dump(config_data, default_flow_style=False))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T11:19:45.759664Z",
     "start_time": "2023-05-31T11:19:45.756737990Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the config file to model, callbacks and datamodule\n",
    "config = get_configurable_parameters(config_path=config_fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T12:25:10.341732259Z",
     "start_time": "2023-05-31T12:25:09.780101330Z"
    }
   },
   "outputs": [],
   "source": [
    "datamodule = get_datamodule(config)\n",
    "datamodule.prepare_data()  # Downloads the dataset if it's not in the specified `root` directory\n",
    "datamodule.setup()  # Create train/val/test/prediction sets.\n",
    "\n",
    "i, data = next(enumerate(datamodule.val_dataloader()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the shapes of the input images and masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"image\"].shape, data[\"mask\"].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could now visualize a normal and abnormal sample from the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_and_mask(sample: dict[str, Any], index: int) -> Image:\n",
    "    img = ToPILImage()(Denormalize()(sample[\"image\"][index].clone()))\n",
    "    msk = ToPILImage()(sample[\"mask\"][index]).convert(\"RGB\")\n",
    "\n",
    "    return Image.fromarray(np.hstack((np.array(img), np.array(msk))))\n",
    "\n",
    "\n",
    "# Visualize an image with a mask\n",
    "show_image_and_mask(data, index=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model and Callbacks\n",
    "\n",
    "Now, the config file is updated as we want. We can now start model training with it. Here we will be using `datamodule`, `model` and `callbacks` to train the model. Callbacks are self-contained objects, which contains non-essential logic. This way we could inject as many callbacks as possible such as ModelLoading, Timer, Metrics, Normalization and Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the export-mode to OpenVINO to create the OpenVINO IR model.\n",
    "config.optimization.export_mode = \"openvino\"\n",
    "# config.optimization.export_mode = \"onnx\"\n",
    "\n",
    "try:\n",
    "    checkpoint_file = experiment.get_artifact('checkpoints')\n",
    "    loaded_checkpoint_path = os.path.join(root_directory, experiment.checkpoint_dir)\n",
    "    checkpoint_file.download(loaded_checkpoint_path)\n",
    "except ResourceNotFoundError as e:\n",
    "    loaded_checkpoint_path = None\n",
    "\n",
    "model = get_model(config)\n",
    "callbacks = get_callbacks(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pytorch_lightning import Callback\n",
    "\n",
    "class SaveTrainingMetrics(Callback):\n",
    "\n",
    "    def on_train_epoch_end(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\") -> None:\n",
    "        experiment.log(name='training_pixel_F1score', type=LogType.LINE,data= float(trainer.callback_metrics['pixel_F1Score']))\n",
    "        experiment.log(name='training_pixel_AUROC', type=LogType.LINE,data= float(trainer.callback_metrics['pixel_AUROC']))\n",
    "        experiment.log(name='training_image_F1Score', type=LogType.LINE,data= float(trainer.callback_metrics['image_F1Score']))\n",
    "        experiment.log(name='training_image_AUROC', type=LogType.LINE,data= float(trainer.callback_metrics['image_AUROC']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T12:25:41.576377857Z",
     "start_time": "2023-05-31T12:25:41.574551325Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class GetMaskPredictions(Callback):\n",
    "    def on_test_batch_end(\n",
    "            self,\n",
    "            trainer: \"pl.Trainer\",\n",
    "            pl_module: \"pl.LightningModule\",\n",
    "            batch: Any,\n",
    "            outputs: Optional[STEP_OUTPUT],\n",
    "            batch_idx: int,\n",
    "            dataloader_idx: int,\n",
    "    ):\n",
    "        test_batch_size = batch[\"image\"].shape[0]\n",
    "        abnormal_dataset = experiment.get_dataset('abnormal')\n",
    "        good_dataset = experiment.get_dataset('good')\n",
    "        label = abnormal_dataset.get_or_create_label('anomaly')\n",
    "\n",
    "        for i in range(test_batch_size):\n",
    "            pred_score = batch[\"pred_scores\"][i].cpu().numpy().item()\n",
    "            gt_mask = batch[\"mask\"][i].squeeze().int().cpu().numpy() if \"mask\" in batch else None\n",
    "            pred_mask = batch[\"pred_masks\"][i].squeeze().int().cpu().numpy() if \"pred_masks\" in batch else None\n",
    "\n",
    "            if len(gt_mask) > 0:  #image is in abnormal dataset\n",
    "                try:\n",
    "                    asset = abnormal_dataset.find_asset(filename=os.path.basename(batch[\"image_path\"][i]))\n",
    "                except:\n",
    "                    print('cannot find the asset')\n",
    "            else:  #image with no gt_mask is in good dataset\n",
    "                asset = good_dataset.find_asset(filename=os.path.basename(batch[\"image_path\"][i]))\n",
    "\n",
    "            try:\n",
    "                gt_annotation = asset.get_annotation()\n",
    "            except:\n",
    "                gt_annotation = asset.create_annotation()\n",
    "\n",
    "            gt_polygons = [(polygon, label) for polygon in\n",
    "                           get_formatted_polygons_from_mask(gt_mask, (asset.width, asset.height))]\n",
    "\n",
    "            if gt_polygons:\n",
    "                gt_annotation.create_multiple_polygons(polygons=gt_polygons)  #attach annotation to asset\n",
    "\n",
    "            pred_polygons = [(polygon, label, pred_score) for polygon in\n",
    "                             get_formatted_polygons_from_mask(pred_mask, (asset.width, asset.height))]\n",
    "\n",
    "            if pred_polygons:\n",
    "                experiment.add_evaluation(asset=asset, polygons=pred_polygons)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "callbacks.insert(len(callbacks),SaveTrainingMetrics())\n",
    "callbacks.insert(len(callbacks),GetMaskPredictions())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T12:25:41.596090190Z",
     "start_time": "2023-05-31T12:25:41.576808323Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T12:25:41.675778233Z",
     "start_time": "2023-05-31T12:25:41.669797584Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(**config.trainer, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if loaded_checkpoint_path:\n",
    "    load_model_callback = LoadModelCallback(weights_path=os.path.join(loaded_checkpoint_path, checkpoint_file.filename))\n",
    "    trainer.callbacks.insert(0, load_model_callback)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T12:25:48.764422849Z",
     "start_time": "2023-05-31T12:25:48.759070647Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.fit(model=model, datamodule=datamodule)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model from checkpoint before evaluating\n",
    "load_model_callback = LoadModelCallback(weights_path=trainer.checkpoint_callback.best_model_path)\n",
    "# load_model_callback = LoadModelCallback(weights_path=os.path.join(loaded_checkpoint_path, checkpoint_file.filename))\n",
    "trainer.callbacks.insert(0, load_model_callback)\n",
    "test_results = trainer.test(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Log test results to Picsellia"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment.log(name=\"test_results\", type=LogType.TABLE, data=test_results[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# log example predictions\n",
    "test_image_path = os.path.join(root_directory,experiment.results_dir,MODEL,dataset_name,'run/images/abnormal')\n",
    "for ele in os.listdir(test_image_path)[:3]:\n",
    "    experiment.log(name='abnormal prediction_'+ele, type=LogType.IMAGE, data=os.path.join(test_image_path,ele))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Log best model's checkpoints to Picsellia"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment.store('checkpoints', trainer.checkpoint_callback.best_model_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Log openvino and onnx models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_root = os.path.join(root_directory, experiment.results_dir, MODEL, dataset_name,'run/weights/openvino/')\n",
    "experiment.store('openvino_metadata', os.path.join(model_root,'metadata.json'))\n",
    "experiment.store('openvino_bin', os.path.join(model_root,'metadata.json'))\n",
    "experiment.store('model_onnx', os.path.join(model_root,'model.onnx'))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae223df28f60859a2f400fae8b3a1034248e0a469f5599fd9a89c32908ed7a84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
